# -*- coding: utf-8 -*-
"""face-gender.ipynb.

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BNvbLIVcv_muAf8r1M9nuZwihj5C_VLI
"""

from torchvision import models
import os
from tqdm.autonotebook import tqdm
from PIL import Image
from IPython.display import clear_output
import matplotlib.pyplot as plt
from torchvision import transforms
import torchvision
from torch.utils.data import DataLoader, Dataset
from torch import optim
from torch import nn
import pandas as pd
import numpy as np
import torch
from google.colab import files
upload = files.upload()

# Commented out IPython magic to ensure Python compatibility.
#  %cd ../
#  %mv dataset4.csv sample_data/
#  %cd sample_data/
# %mkdir train
# %mkdir test
# %mkdir train/male
# %mkdir train/female
# %mkdir test/male
# %mkdir test/female
!unzip images_faces.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd sample_data/
# %ls


# Модуль с блоками и функциями нейронных сетей

# Модуль с оптимизаторами


# Модуль с датасетами и моделями для компютерного зрения


transform = transforms.Compose([
    transforms.RandomRotation(20),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

names = os.listdir('lfw')
names1 = names[:1500]
names2 = names[1500:3000]
names3 = names[3000:4500]
names4 = names[4500:5200]
testnames = names[5200:]
data1 = pd.read_csv('dataset1.csv').drop(['Unnamed: 0'], axis=1)
data2 = pd.read_csv('dataset2.csv').drop(['Unnamed: 0'], axis=1)
data3 = pd.read_csv('dataset3.csv').drop(['Unnamed: 0'], axis=1)
data4 = pd.read_csv('dataset4.csv').drop(['Unnamed: 0'], axis=1)

data = pd.concat([data1, data2, data3, data4], axis=0)

data

for name in tqdm(names1):
    for pic in os.listdir('lfw/'+name):
        if '3.0' in pic:
            pass
        else:
            try:
                gender = data[data.Image == pic]
                if gender.values[0][1] == 'male':
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/male/{}'.format(pic))
                else:
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/female/{}'.format(pic))
            except:
                pass

for name in tqdm(names2):
    for pic in os.listdir('lfw/'+name):
        if '3.0' in pic:
            pass
        else:
            try:
                gender = data[data.Image == pic]
                if gender.values[0][1] == 'male':
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/male/{}'.format(pic))
                else:
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/female/{}'.format(pic))
            except:
                pass

for name in tqdm(names3):
    for pic in os.listdir('lfw/'+name):
        if '3.0' in pic:
            pass
        else:
            try:
                gender = data[data.Image == pic]
                if gender.values[0][1] == 'male':
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/male/{}'.format(pic))
                else:
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/female/{}'.format(pic))
            except:
                pass

for name in tqdm(names4):
    for pic in os.listdir('lfw/'+name):
        if '3.0' in pic:
            pass
        else:
            try:
                gender = data[data.Image == pic]
                if gender.values[0][1] == 'male':
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/male/{}'.format(pic))
                else:
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'train/female/{}'.format(pic))
            except:
                pass

for name in tqdm(testnames):
    for pic in os.listdir('lfw/'+name):
        if '3.0' in pic:
            pass
        else:
            try:
                gender = data[data.Image == pic]
                if gender.values[0][1] == 'male':
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'test/male/{}'.format(pic))
                else:
                    os.rename('lfw/{}/{}'.format(name, pic),
                              'test/female/{}'.format(pic))
            except:
                pass

print(len(os.listdir('train/female')))
print(len(os.listdir('train/male')))

males = os.listdir('train/male')
for i in range(18527-5916):
    os.remove('train/male/'+males[i])

males = os.listdir('test/male')
for i in range(2049-595):
    os.remove('test/male/'+males[i])

TRAIN_DATA_PATH = 'train'
TEST_DATA_PATH = 'test'
BATCH_SIZE = 64
train_data = torchvision.datasets.ImageFolder(
    root=TRAIN_DATA_PATH, transform=transform)
train_data_loader = torch.utils.data.DataLoader(
    train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)
test_data = torchvision.datasets.ImageFolder(
    root=TEST_DATA_PATH, transform=transform)
test_data_loader = torch.utils.data.DataLoader(
    test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)

resnet = models.resnet50(True)
# resnet2 = models.resnet34(True)

resnet

for param in resnet.parameters():
    param.requires_grad = False

resnet.fc = nn.Linear(2048, 2)
resnet.fc.requires_grad_(True)
resnet.layer4.requires_grad_(True)

opt = optim.Adam(resnet.parameters())

print(len(train_data_loader))
print(len(test_data_loader))

model = resnet
epoch_num = 10
#opt = cnn_opt

# Массивы для метрик

train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []
loss_func = nn.CrossEntropyLoss()


# Основной цикл по эпохам
for epoch in range(epoch_num):

    # Массивы для промежуточных метрик
    losses = []
    accuracies = []

    model.train()
    # Цикл обучения
    for i, (X, y) in tqdm(enumerate(train_data_loader)):

        # Обучение модели
        pred = model(X)
        loss = loss_func(pred, y)
        opt.zero_grad()
        loss.backward()
        opt.step()
        losses.append(loss.item())
        acc = (pred.argmax(-1) == y).float().mean()
        accuracies.append(acc.item())

    train_losses.append(np.mean(losses))
    train_accuracies.append(np.mean(accuracies))
    losses = []
    accuracies = []

    # Validation
    model.eval()
    with torch.no_grad():
        for j, (X_test, y_test) in tqdm(enumerate(test_data_loader)):

            pred = model(X_test)
            loss = loss_func(pred, y_test)
            losses.append(loss.item())
            acc = (pred.argmax(-1) == y_test).float().mean()
            accuracies.append(acc.item())

    test_losses.append(np.mean(losses))
    test_accuracies.append(np.mean(accuracies))

    # Очищаем то что нарисовано
    clear_output(True)
    # Создаём новый график
    plt.figure()
    # Рисуем лосс
    steps = range(len(train_losses))

    plt.plot(steps, train_losses, label='Train loss')
    plt.plot(steps, test_losses, label='Validation loss')

    plt.legend()
    plt.title('Loss')
    # Создаём новый график
    plt.figure()
    # Рисуем accuracy
    plt.plot(steps, train_accuracies, label='Train accuracy')
    plt.plot(steps, test_accuracies, label='Validation accuracy')

    plt.legend()
    plt.title('Accuracy')

    # Показываем в тетрадке
    plt.show()

    print(epoch, '|', 'Train loss:', train_losses[-1], '|', 'Train accuracy:', train_accuracies[-1],
          '|', 'Val loss:', test_losses[-1], '|', 'Val accuracy:', test_accuracies[-1])

torch.save(resnet.state_dict(), 'home')

files.download('home')
